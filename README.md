# TEXT2SQL-EHRSQL
This work builds on top of the datasets released with https://github.com/glee4810/EHRSQL. Use the instructions mentioned in the link to download the database and the datasets. 

## Set up Environment

Set up conda environment using (python>=3.10):

```
pip install -r requirements.txt
```

## Training
Two models are used in this work - Mistral and Llama 2. Download the models from the link below:
Mistral7B : https://huggingface.co/mistralai/Mistral-7B-v0.1
Llama27B  : https://huggingface.co/meta-llama/Llama-2-7b

The training to reproduce the results can be performed using the following command:

#### No Predicting tables or keys 
Note: Pass the path of the model, the learning rate, the dataset path, output directory, model name and dataset name as parameters to the script.  The training set for both the datasets are assumed to be named 'train_mimic.json' , 'train_eicu.json'. Change the name in the bash command according to the file name.

##### Model Mistral, Dataset Mimic:
```
bash run.sh https://huggingface.co/mistralai/Mistral-7B-v0.1 1e-5 train_mimic.json ./mistral_main_prompt_mimic/ mistral mimic
```

##### Model Mistral, Dataset EICU:
```
bash run.sh https://huggingface.co/mistralai/Mistral-7B-v0.1 1e-5 train_eicu.json ./mistral_main_prompt_eicu/ mistral eicu
```

##### Model Llama2, Dataset Mimic:
```
bash run.sh https://huggingface.co/meta-llama/Llama-2-7b 1e-5 train_mimic.json ./llama2_main_prompt_mimic/ mistral eicu
```

##### Model Llama2, Dataset EICU:
```
bash run.sh https://huggingface.co/meta-llama/Llama-2-7b 1e-5 train_eicu.json ./llama2_main_prompt_eicu/ mistral eicu
```

#### Predicting tables and keys 
```
bash run_multi.sh https://huggingface.co/mistralai/Mistral-7B-v0.1 1e-5 train_multistep.json ./mistral_multitool_prompt/ mistral
```
Note: Pass the path to the model , the learning rate , the dataset path , output directory and model name as parameters to the script. 

## Inference
Go to the inference folder for instructions to perform inference on the development set.

## Evaluation 
For evalauting the code generated by the finetuned models we follow the same method that is used in  [EHRSQL](https://github.com/glee4810/EHRSQL?tab=readme-ov-file#evaluation). Refer to the link and follow the same procedure for evaluation. 
